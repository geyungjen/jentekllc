{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed Apache Arrow Python library for flight\n",
    "\n",
    "from pyarrow import flight\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Dremio Client Authentication Methods\n",
    "\n",
    "class HttpDremioClientAuthHandler(flight.ClientAuthHandler):\n",
    "\n",
    "    def __init__(self, username, password):\n",
    "        super(flight.ClientAuthHandler, self).__init__()\n",
    "        self.basic_auth = flight.BasicAuth(username, password)\n",
    "        self.token = None\n",
    "\n",
    "    def authenticate(self, outgoing, incoming):\n",
    "        auth = self.basic_auth.serialize()\n",
    "        outgoing.write(auth)\n",
    "        self.token = incoming.read()\n",
    "\n",
    "    def get_token(self):\n",
    "        return self.token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'george'\n",
    "password = '<redacted>'\n",
    "sql = '''select * from \"fraud.dremio\".SMSSpamCollection'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to Dremio with flight connector on port 47470 mentions earlier in the writing\n",
    "\n",
    "client = flight.FlightClient('grpc+tcp://10.0.2.15:47470')\n",
    "client.authenticate(HttpDremioClientAuthHandler(username, password)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passing in SQL query statement to Dremio, execute and returns the data in pandas dataframe pdf\n",
    "info = client.get_flight_info(flight.FlightDescriptor.for_command(sql))\n",
    "reader = client.do_get(info.endpoints[0].ticket)\n",
    "batches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "while True: \n",
    "    try:\n",
    "        batch, metadata = reader.read_chunk()\n",
    "        batches.append(batch)\n",
    "    except StopIteration:\n",
    "        break\n",
    "data = pa.Table.from_batches(batches)\n",
    "pdf = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A                                                  B\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys,os,os.path\n",
    "os.environ['SPARK_HOME']='/opt/spark/'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the pandas dataframe to SparkSQL dataframe\n",
    "sqlCtx = SQLContext(sc)\n",
    "df = sqlCtx.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|   A|                   B|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|status|message                                                                                                                                                    |\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham   |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                            |\n",
      "|ham   |Ok lar... Joking wif u oni...                                                                                                                              |\n",
      "|spam  |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's|\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Note: Spam is Spam, Han is OK. Rename Column name A as status, B as feature\n",
    "\n",
    "df = df.withColumnRenamed('A', 'status').withColumnRenamed('B', 'message')\n",
    "df.show(3, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  1.0|Go until jurong p...|\n",
      "|  1.0|Ok lar... Joking ...|\n",
      "|  0.0|Free entry in 2 a...|\n",
      "|  1.0|U dun say so earl...|\n",
      "|  1.0|Nah I don't think...|\n",
      "|  0.0|FreeMsg Hey there...|\n",
      "|  1.0|Even my brother i...|\n",
      "|  1.0|As per your reque...|\n",
      "|  0.0|WINNER!! As a val...|\n",
      "|  0.0|Had your mobile 1...|\n",
      "|  1.0|I'm gonna be home...|\n",
      "|  0.0|SIX chances to wi...|\n",
      "|  0.0|URGENT! You have ...|\n",
      "|  1.0|I've been searchi...|\n",
      "|  1.0|I HAVE A DATE ON ...|\n",
      "|  0.0|XXXMobileMovieClu...|\n",
      "|  1.0|Oh k...i'm watchi...|\n",
      "|  1.0|Eh u remember how...|\n",
      "|  1.0|Fine if thats th...|\n",
      "|  0.0|England v Macedon...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Encode status column to numeric: ham to 1.0 and spam to 0. \n",
    "#All our fields need to be numeric for machine to learn, also rename the column status to label\n",
    "\n",
    "df.createOrReplaceTempView('temp')\n",
    "df = spark.sql('select case status when \"ham\" then 1.0  else 0 end as label, message from temp')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|             message|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1 is OK, 0 is Spam\n",
    "#Tokenize the messages Tokenization is the process of taking text (such as a sentence) \n",
    "# and breaking it into individual terms (usually words). Let’s tokenize the messages \n",
    "#and create a list of words of each message. \n",
    "\n",
    "\n",
    "from pyspark.ml.feature import  Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"message\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "wordsData.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|             message|               words|         rawFeatures|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|  1.0|Go until jurong p...|[go, until, juron...|(13587,[8,43,53,6...|\n",
      "|  1.0|Ok lar... Joking ...|[ok, lar..., joki...|(13587,[5,76,409,...|\n",
      "|  0.0|Free entry in 2 a...|[free, entry, in,...|(13587,[0,3,8,22,...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer converts a collection of text documents to vectors of token counts.\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "count = CountVectorizer (inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "model = count.fit(wordsData)\n",
    "featurizedData = model.transform(wordsData)\n",
    "featurizedData.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(13587,[8,43,53,6...|\n",
      "|  1.0|(13587,[5,76,409,...|\n",
      "|  0.0|(13587,[0,3,8,22,...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#IDF reduces the features that often appear in the corpus. When using text as a feature, \n",
    "#this usually improves performance because the most common, \n",
    "#and therefore less important, words are weighted down\n",
    "\n",
    "from pyspark.ml.feature import  IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.select(\"label\", \"features\").show(3)  #Only needed to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly Split DataFrame into 80% Training (trainDF) and 20 Testing (testDF)\n",
    "\n",
    "seed = 0  # random seed 0\n",
    "trainDF, testDF = rescaledData.randomSplit([0.8,0.2],seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3853"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression classifier\n",
    "\n",
    "#Logistic regression is a common method of predicting classification responses. \n",
    "#A special case of a generalized linear model is the probability of predicting a result. \n",
    "#In spark.ml, logistic regression can be used to predict binary results \n",
    "#by binomial logistic regression, or it can be used to predict multiple types of results by using multiple logistic regression. \n",
    "#Use the family parameter to choose between these two algorithms, or leave it unset and Spark will infer the correct variable.\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import numpy as np\n",
    "lr = LogisticRegression(maxIter = 100)\n",
    "\n",
    "model_lr = lr.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lr = model_lr.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734030197444833"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval_lr = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "my_eval_lr.evaluate(prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9654997463216642"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_lr = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "my_mc_lr.evaluate(prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967479674796748"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mc_lr = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_lr.evaluate(prediction_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       1.0|   31|\n",
      "|  1.0|       1.0|  860|\n",
      "|  0.0|       0.0|   92|\n",
      "|  1.0|       0.0|    1|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_fit_lr = prediction_lr.select('label','prediction')\n",
    "train_fit_lr.groupBy('label','prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Naive Bayesian classifiers are a class of simple probability classifiers that apply strong (naive) \n",
    "#independent assumptions between features based on Bayes' theorem. The spark.ml implementation \n",
    "#currently supports polynomial naive Bayes and Bernoulli Naïve Bayes.\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes()\n",
    "Model_nb = nb.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "|  0.0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_nb = Model_nb.transform(testDF)\n",
    "predictions_nb.select('label', 'prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.937862950058072"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_eval_nb = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', metricName='areaUnderROC')\n",
    "my_eval_nb.evaluate(predictions_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.933544453535483"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_mc_nb = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1')\n",
    "my_mc_nb.evaluate(predictions_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9278455284552846"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mc_nb = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_mc_nb.evaluate(predictions_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
